{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE WILL WORK WITH BINARY DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing\n",
    "(for black and white images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import important libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the paths to the directories for train and test images and masks\n",
    "train_set_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/train_set/'\n",
    "test_set_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/test_set/'\n",
    "\n",
    "original_train_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/train_set/original_images/'\n",
    "original_test_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/test_set/original_images/'\n",
    "mask_train_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/train_set/images_semantic/'\n",
    "mask_test_path = '/home/harshveer.singh/Downloads/drone_dataset/archive/binary_dataset/images/test_set/images_semantic/'\n",
    "\n",
    "# List all files in the train_path directory\n",
    "train_ids = [filename for filename in os.listdir(original_train_path) if os.path.isfile(os.path.join(original_train_path, filename))]\n",
    "\n",
    "test_ids = [filename for filename in os.listdir(original_test_path) if os.path.isfile(os.path.join(original_test_path, filename))]\n",
    "\n",
    "#The order might be jumbled\n",
    "print(\"TRAIN PATHS :\", train_ids)\n",
    "print(\"TEST PATHS\",test_ids)\n",
    "\n",
    "\n",
    "np.random.seed = 42\n",
    "\n",
    "#Dimentions to be used to resize all the images\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "img_channels = 3\n",
    "\n",
    "#READ ALL THE IMAGES AND RESIZE THEM TO 128x128\n",
    "x_train = np.zeros((len(train_ids), img_height,img_width,img_channels), dtype = np.uint8)\n",
    "y_train = np.zeros((len(train_ids), img_height,img_width,1), dtype = np.bool_) #boolean - we want a yes or no answer\n",
    "\n",
    "\n",
    "print(\"RESIZING TRAINING IMAGES\")\n",
    "for n,id_ in tqdm(enumerate(train_ids), total = len(train_ids)):   #tqdm just gives a progress bar\n",
    "    \n",
    "    path = original_train_path   #will give the path to the folder with the image\n",
    "    img = imread(path +id_)[:,:,:img_channels]   #then go to the 'images' subfolder and add the image\n",
    "\n",
    "    img = resize(img,(img_height,img_width), mode='constant',preserve_range=True)\n",
    "    x_train[n] = img\n",
    "\n",
    "\n",
    "\n",
    "print(\"RESIZING MASKS\")\n",
    "train_ids_masks= [filename for filename in os.listdir(mask_train_path) if os.path.isfile(os.path.join(mask_train_path, filename))]\n",
    "\n",
    "test_ids_masks = [filename for filename in os.listdir(mask_test_path) if os.path.isfile(os.path.join(mask_test_path, filename))]\n",
    "\n",
    "\n",
    "for n,id_ in tqdm(enumerate(train_ids_masks), total = len(train_ids)):   #tqdm just gives a progress bar\n",
    "    \n",
    "    path = mask_train_path   #will give the path to the folder fro the image\n",
    "    masks_ = imread(path + id_)\n",
    "    masks_ = np.expand_dims(resize(masks_,(img_height,img_width),mode='constant',preserve_range=True), axis =-1)\n",
    "    y_train[n] = masks_\n",
    "\n",
    "\n",
    "\n",
    "# print(\"X train data type \",x_train.dtype)\n",
    "# print(\"Y train data type \",y_train.dtype)\n",
    "\n",
    "\n",
    "x_test = np.zeros((len(test_ids), img_height,img_width,img_channels), dtype = np.uint8)\n",
    "\n",
    "print(\"RESIZING testing IMAGES \")\n",
    "\n",
    "for n,id_ in tqdm(enumerate(test_ids), total = len(test_ids)):   #tqdm just gives a progress bar\n",
    "\n",
    "        path = original_test_path   #will give the path to the folder fro the image\n",
    "        img = imread(path +id_)[:,:,:img_channels]   #then go to the 'images' subfolder and add the image\n",
    "\n",
    "\n",
    "        img = resize(img,(img_height,img_width), mode='constant',preserve_range=True)\n",
    "        x_test[n] = img\n",
    "\n",
    "print(\"DONE!!!\")\n",
    "\n",
    "\n",
    "#UNCOMMENT TO PERFORM A SANITY CHECK\n",
    "#image_x = random.randint(0,len(train_ids))\n",
    "#imshow(x_train[image_x])\n",
    "#plt.show()\n",
    "#\n",
    "#imshow(np.squeeze(y_train[image_x]))\n",
    "#plt.show()\n",
    "#\n",
    "#print(\"Image ID\",image_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing (for coloured binary images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "# Define image dimensions\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "img_channels = 3\n",
    "\n",
    "# Path to your dataset\n",
    "image_path = '/home/harshveer.singh/Downloads/Kitti_dataset/data_road_224/training/image_2/'\n",
    "mask_path = '/home/harshveer.singh/Downloads/Kitti_dataset/data_road_224/training/gt_image_2/'\n",
    "\n",
    "train_ids = [filename for filename in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, filename))]\n",
    "train_ids_masks= [filename for filename in os.listdir(mask_path) if os.path.isfile(os.path.join(mask_path, filename))]\n",
    "# Function to load images and masks\n",
    "def load_data(image_path, mask_path):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for n,id_ in tqdm(enumerate(train_ids), total = len(train_ids)): \n",
    "        path = image_path   #will give the path to the folder fro the image\n",
    "        \n",
    "        img = cv2.imread(path +id_)#[:,:,:img_channels]   #then go to the 'images' subfolder and add the image\n",
    "        \n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        images.append(img)\n",
    "\n",
    "        path = mask_path   #will give the path to the folder fro the image\n",
    "        mask = cv2.imread(path +\"gt_\"+ id_)\n",
    "        mask = cv2.resize(mask, (img_width, img_height))\n",
    "        #My images are purple and yellow. Adjust the below value according to need\n",
    "        road_mask = cv2.inRange(mask, (128, 0, 128), (128, 0, 128))  # Purple color range (background colour)\n",
    "        road_mask = road_mask // 255  # Normalize to binary values (0 and 1)\n",
    "        masks.append(road_mask)     \n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "x_train, y_train = load_data(image_path, mask_path)\n",
    "\n",
    "# Normalize the images\n",
    "x_train = x_train / 255.0\n",
    "y_train = np.expand_dims(y_train, axis=-1)  # Expand dimensions for masks\n",
    "\n",
    "print(f\"Images shape: {x_train.shape}\")\n",
    "print(f\"Masks shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precdictions for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./image_segmentation_model.h5')\n",
    "\n",
    "ix = random.randint(0,len(x_train))\n",
    "\n",
    "preds_train = model.predict(x_train[:int(x_train.shape[0]*0.9)],verbose=1)\n",
    "preds_val = model.predict(x_train[int(x_train.shape[0]*0.9):],verbose=1)\n",
    "preds_test = model.predict(x_test,verbose=1)\n",
    "\n",
    "preds_train_t = (preds_train>0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val>0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test>0.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "#sanity check on some random train sample\n",
    "ix = random.randint(0,len(preds_train_t))\n",
    "imshow(x_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()\n",
    "\n",
    "#sanity check on some validation sample \n",
    "ix = random.randint(0,len(preds_val_t))\n",
    "imshow(x_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Load your test images and ground truth masks\n",
    "# Assuming x_test and y_test are already loaded\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_test = model.predict(x_test, verbose=1)\n",
    "\n",
    "# Apply binary thresholding\n",
    "#preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "preds_test=preds_test.astype(np.uint8)\n",
    "# Function to visualize the results\n",
    "def visualize_results(x, y_pred, idx):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(x[idx])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # # Ground truth mask (wont have these for test set)\n",
    "    # plt.subplot(1, 3, 2)\n",
    "    # plt.title(\"Ground Truth Mask\")\n",
    "    # plt.imshow(np.squeeze(y_true[idx]), cmap='gray')\n",
    "    # plt.axis('off')\n",
    "   \n",
    "    \n",
    "    # Predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(np.squeeze(y_pred[idx]),cmap='gray')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions for a few random test images\n",
    "num_samples = 5  # Number of samples to visualize\n",
    "for _ in range(num_samples):\n",
    "    idx = random.randint(0, len(x_test) - 1)\n",
    "    visualize_results(x_test, preds_test_t, idx)\n",
    "\n",
    "\n",
    "# Download some random images and test\n",
    "image1 = imread('/Downloads/image1.jpeg')[:,:,:img_channels]   \n",
    "image1 = resize(image1,(img_height,img_width), mode='constant',preserve_range=True)\n",
    "\n",
    "image2 = imread('/Downloads/image2.jpeg')[:,:,:img_channels]\n",
    "\n",
    "image2 = resize(image2,(img_height,img_width), mode='constant',preserve_range=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_test_images = np.zeros((2, img_height,img_width,img_channels), dtype = np.uint8)\n",
    "random_test_images[0] = image1\n",
    "random_test_images[1] = image2\n",
    "\n",
    "\n",
    "\n",
    "print(\"New test images ....\")\n",
    "new_preds_test = model.predict(random_test_images, verbose=1)\n",
    "\n",
    "for i in range(5):\n",
    "    visualize_results(random_test_images, new_preds_test, i)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
